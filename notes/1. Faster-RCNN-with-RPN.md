# 《Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks》阅读笔记

## 简介

Fast R-CNN 等模型优化了监测网络，但在 Selective Search 选定 region proposal 的时候效率太低，于是 Faster R-CNN 提出 RPN 直接卷积特征图预设锚框，把预设部分合并原来的 Fast R-CNN 的检测部分放在一起训练，极大提升了效率与精度。

> 端到端训练：整个系统从输入到输出所有步骤都是可训练且联合优化的。

## 背景

目前获取 region proposal 的最流行的方法是 selective search，它的核心是贪心算法。

> 先用图像分割算法把图片分割为一些小超像素（即一些颜色和纹理等底层特征相似的部分）。对于所有相邻的超像素对，找出相似度最高的两个区域（_贪心_）合并为新区域，移除这两个区域的所有相关项，把新区域和相邻区域纳入运算，一直循环。

这种运算明显是在 CPU 上跑的，算法本身和不能多线程运算都决定了它慢（CPU 上 2s/图），拖累了整个模型的速度；而且贪心容易陷入局部最优，也处理不了复杂的图像。
新方法 edgeboxes 稍微好一点，但是因为在 CPU 上跑，并且不能结合语义，所以精度效率都不好。
如果实现为在 GPU 上面跑呢？但是不把它和后面的 detection network 架设到一起共享权重，好像浪费了；并且发现 CNN 提取的特征还可以帮助生成 region proposal ，所以 RPN 就这样干了。

目标检测时多尺度处理是一个重要的部分。常见的三种处理关系：

1. 图像金字塔和特征金字塔
   缩放出来多个尺度的图像，分别提取特征，单独检测（非常慢）
2. 滤波器金字塔
   使用多个不同尺寸或者比例的 filter 来检测不同尺度物体（因为需要事先设定多个滤波器，参数冗余，灵活性差）
3. <span style="color:#ff0000;">参考框（锚框）金字塔</span>
   事先对单尺度图上提取到的特征设定多个 archor（archor 的超参数需要事先定义），对每个 archor 预测分类得分和回归偏移量。灵活且高效率。

Faster R-CNN 采用第三种。

## 实现

Faster R-CNN 由两个部分组成。一个是 Fast R-CNN 的预测模块，一个是 RPN。RPN 就好像“注意力机制”一样提醒预测模块要注意什么，预测出来的结果反向传播时又能够同时训练预测模块和 RPN 的性能。

### RPN

用于特征提取的卷积层是被共享的，然后再分支。
生成候选区域时，用一个 $n \times n$（通常取$ n=3 $）卷积层去对特征图卷积，然后再用两个$ 1 \times 1 $ 卷积层分离特征，流入回归分支和分类分支。

![Fast R-CNN](https://github.com/mingqian-233/CV-Notes/blob/master/images/faster_rcnn.png?raw=true)

#### 锚框

$ 3 \times 3$ 层滑动的时候，会以滑动窗口为中心，生成若干个锚框（这些锚框可以被映射回原图，它们大致捕获了图像的特征）。锚框的个数如下：
\[\text{单点锚框个数} = \text{尺度个数} \times \text{缩放比个数} \\
\text{总锚框个数} = \text{单点锚框个数} \times \text{特征图大小}\]

> 1. 该方法下的锚框具有平移不变性；
> 2. 这种“锚框金字塔”稳定获取多尺度的同时可以节省效率，也有利于共享特征。

#### RPN 的损失函数

训练 RPN 时，每个锚点会被分配 Positive/Negative label，遵循规则如下：

1. 与其对应的真实框和它的 IoU 中，是真实框所有匹配到的锚框的 IoU 中最大的；**或者**和对应的真实框的 IoU $\geq$ 0.7，则为正标签；
2. IoU < 0.3，则为负标签；
3. 不符合上述两点的，直接忽视掉。

> 显然这个分配方法在计算 IoU 的时候对应的复杂度为平方级别的$O(NM)$，其中$N$为真实框个数，$M$为锚框个数。但其实一般来说 N 都很小，运算次数并不会很多。

训练 RPN 时，对于一整个 mini_batch，损失函数的计算公式很好理解，就是把分类的损失和<span style="color:#ff0000;font-weight:bold">正样本</span>的位置回归的损失带权加在一起。
公式为：

$$
L(\{p_i\}, \{t_i\}) = \frac{1}{N_{\text{cls}}} \sum_i L_{\text{cls}}(p_i, p_i^*) + \lambda \frac{1}{N_{\text{reg}}} \sum_i p_i^* L_{\text{reg}}(t_i, t_i^*)
$$

$$
p_i：预测模型的结果，二分类概率，表示框里面有一个需要检测的目标的置信度\\
p_i^*：0 表示锚框是负样本，1 表示锚框是正样本\\
t_i,t_i^*：分别是锚框和真实框的位置表示\\
N_{cls}：归一化项，和\text{mini-batch}中的锚框数量相等\\
N_{reg}：特征图尺寸（锚框位置数）\\
\lambda：超参数，并不敏感，论文中设为10\\
L_{cls}：对数损失\\
L_{reg}：smooth{\space}L_1损失
$$

${smooth \space L_1}$公式如下：

$$
L_{\text{reg}} =
\begin{cases}
0.5 (t - t^*)^2 / \beta, & \text{if } |t - t^*| < \beta \\
|t - t^*| - 0.5 \beta, & \text{otherwise}
\end{cases}
$$

> 这里的$p_i$和分类无关，因为训练这一部分的目的仅仅是生成高质量的 region proposal，不用关心类别。
> 两部分的归一化策略并不相同，因为其本身的任务衡量损失的方向不一样。前者需要平衡正负样本，后者需要统计整个图片的框的分布。

对于边界框回归，有下面的参数化表示。

对预测框：

$$
t_x = \frac{x - x_a}{w_a},
t_y = \frac{y - y_a}{h_a}, \\
t_w = \log\left(\frac{w}{w_a}\right),
t_h = \log\left(\frac{h}{h_a}\right)
$$

对真实框：

$$
t^*_x = \frac{x^* - x_a}{w_a},
t^*_y = \frac{y^* - y_a}{h_a}, \\
t^*_w = \log\left(\frac{w^*}{w_a}\right),
t^*_h = \log\left(\frac{h^*}{h_a}\right)
$$

所有带下标$_a$的都是锚框的参数，相当于和锚框的相对偏移量。除以锚框的宽和高是为了实现尺度不变性。

> Fast R-CNN 的 RPN 的边界框回归和先前基于 RoI 的方法的差异：对特征处理不池化，直接在固定尺寸的特征图上滑动 filter，并且不同尺度和长宽比的锚框使用不同的 filter。这样不会因为池化丢弃细节，同时也能区分尺度不同的物体。

#### RPN 的训练

用经典的 SGD 训练。采样策略是 Fast R-CNN 的“image-centric”。

> image-centric：以单张图像为单位构建 mini-batch，通过平衡正负样本比例来高效训练模型。每张图片采样固定数量的锚框组成一个 mini-batch，并且优先正采样，让正负样本数量趋于 1:1（如果不这样做的话会采样到很多背景的负采样）。

新提出的层用均值为 $ \mu = 0 $，标准差为 $ \sigma = 0.01 $ 的高斯分布随机初始化权重参数。共享的卷积层（传统的层）和标准做法相同。
底层卷积层的作用是学习特征，这些特征可以用于迁移学习。所以直接用 ImageNet 上训练好的模型初始化。

### RPN 和 Fast R-CNN 的共享特征

检测网络使用的是 Fast R-CNN。RPN 和检测网络修改卷积的方式看起来是不一样的，那它们如何共享卷积层呢？方法有三：

1. 交替训练
   先训练 RPN，再用 RPN 生成 region proposal 来训练 Fast R-CNN，再用优化后的 Fast R-CNN 初始化 RPN……循环往复。
2. 近似联合训练
   把两个网络合并在一起，前向传播时产生 region proposal，**被视为固有的**用来训练 Fast R-CNN。反向传播的时候，梯度不反向传播到 RPN 的候选生成部分——即 Fast R-CNN 的梯度仅影响自身和共享卷积层部分，RPN 的更新通过上述的分类和回归损失更新。
   > 这里的“近似”，指的是忽略了 NMS 的反向传播，而且候选框的坐标已经被固定了。
3. 非近似联合训练
   RPN 预测的边界框实际上也属于输入的函数，RoI 层同时接受卷积特征和 region proposal 作为输入，反向传播理应包含它们的梯度，所以需要一个与框坐标可微分的 RoI 池化层。这个问题并不在本文讨论的范围。

#### 四步交替训练

训练 RPN（端到端微调）$\xrightarrow{\text{得到region proposal}}$ 用另外一个初始的共享卷积层训练 Fast R-CNN
$\xrightarrow{用它的共享卷积层初始化}$保持共享卷积层不变，仅微调 RPN 特有的层 $\xrightarrow{}$保持共享卷积层不变，仅微调 Fast R-CNN 特有的层

### 实现细节

- 用图像金字塔可以提高精度，但效率和准确率的平衡不好。
- 锚点使用三个尺度和三个纵横比，这些超参数并没有精心选择。
- 训练时超出图像边界的锚框在训练中全部被忽略。如果不忽略，则容易不收敛。测试时产生的超过边界的则被裁切。
- 采用 NMS，阈值为 0.7。NMS 在不损失检测精度的时候大幅减少了 region proposal 的数量。
